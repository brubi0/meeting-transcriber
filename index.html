<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="theme-color" content="#667eea">
    <title>Meeting Transcriber</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 10px;
        }

        /* Mobile optimizations */
        @media (max-width: 768px) {
            body {
                padding: 5px;
            }
            
            h1 {
                font-size: 1.8em !important;
            }
            
            .card {
                padding: 15px !important;
            }
            
            header {
                padding: 20px !important;
            }
            
            button {
                font-size: 14px !important;
                padding: 12px 25px !important;
                width: 100%;
                margin: 5px 0;
            }
            
            .controls {
                display: flex;
                flex-direction: column;
                gap: 10px;
            }
            
            .ai-actions {
                flex-direction: column !important;
            }
            
            .btn-ai {
                width: 100%;
            }
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        header {
            background: white;
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            margin-bottom: 20px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        h1 {
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .subtitle {
            color: #7f8c8d;
            font-size: 1.1em;
        }

        .card {
            background: white;
            padding: 30px;
            border-radius: 15px;
            margin-bottom: 20px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .api-key-section {
            margin-bottom: 20px;
        }

        .api-key-section input {
            width: 100%;
            padding: 15px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 16px;
            margin-top: 10px;
        }

        .api-key-section input:focus {
            outline: none;
            border-color: #667eea;
        }

        .controls {
            text-align: center;
            margin: 30px 0;
        }

        button {
            padding: 15px 40px;
            font-size: 18px;
            font-weight: bold;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-start {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-start:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 7px 20px rgba(0,0,0,0.3);
        }

        .btn-stop {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
        }

        .recording-indicator {
            margin-top: 20px;
            font-size: 20px;
            color: #e74c3c;
            font-weight: bold;
        }

        .pulse {
            display: inline-block;
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }

        .transcript-box {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            min-height: 200px;
            white-space: pre-wrap;
            line-height: 1.8;
            font-size: 16px;
            border: 2px solid #e9ecef;
        }

        .transcript-list {
            margin-top: 30px;
        }

        .transcript-item {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 15px;
            border: 2px solid #e9ecef;
            cursor: pointer;
            transition: all 0.3s;
        }

        .transcript-item:hover {
            border-color: #667eea;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .transcript-title {
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .transcript-preview {
            color: #7f8c8d;
            font-size: 14px;
        }

        .btn-export {
            background: #3498db;
            color: white;
            padding: 8px 20px;
            margin-top: 10px;
            border-radius: 5px;
            font-size: 14px;
        }

        .ai-actions {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            margin-top: 15px;
            padding-top: 15px;
            border-top: 2px solid #e9ecef;
        }

        .btn-ai {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 10px 20px;
            border-radius: 8px;
            font-size: 14px;
            border: none;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-ai:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        }

        .btn-ai:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .ai-result {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-top: 15px;
            border: 2px solid #667eea;
            white-space: pre-wrap;
            line-height: 1.6;
        }

        .ai-loading {
            text-align: center;
            padding: 20px;
            color: #667eea;
            font-style: italic;
        }

        .error {
            background: #fee;
            color: #c00;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            border: 2px solid #fcc;
        }

        .success {
            background: #efe;
            color: #0a0;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            border: 2px solid #cfc;
        }

        .empty-state {
            text-align: center;
            color: #95a5a6;
            padding: 40px;
            font-size: 18px;
        }

        h3 {
            color: #2c3e50;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üé§ Meeting Transcriber</h1>
            <p class="subtitle">Real-time transcription with English/Spanish support</p>
        </header>

        <div class="card">
            <div class="api-key-section">
                <label for="apiKey"><strong>Deepgram API Key:</strong></label>
                <input 
                    type="password" 
                    id="apiKey" 
                    placeholder="Enter your Deepgram API key"
                    value="">
                <p style="font-size: 12px; color: #7f8c8d; margin-top: 5px;">
                    Get your free API key at <a href="https://console.deepgram.com/signup" target="_blank">console.deepgram.com</a>
                </p>
            </div>

            <div style="background: #fff3cd; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 4px solid #ffc107;">
                <strong>üéØ Two Ways to Transcribe:</strong><br>
                <strong>1. Live Recording</strong> - Click "Start Recording" below (captures microphone only)<br>
                <strong>2. Upload File</strong> - Upload a recorded meeting file (Zoom, Teams, etc.)
            </div>

            <div style="background: #e8f5e9; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 4px solid #4caf50;">
                <strong>üí° AI Analysis Tip:</strong> After transcribing, use the analysis buttons to export prompts. 
                Copy and paste the exported text into <a href="https://claude.ai" target="_blank">claude.ai</a> for free AI analysis with your Claude subscription!
            </div>

            <div id="message"></div>

            <!-- File Upload Section -->
            <div style="border: 2px dashed #667eea; border-radius: 10px; padding: 20px; text-align: center; margin-bottom: 20px; background: #f8f9ff;">
                <h3 style="margin-top: 0; color: #667eea;">üìÅ Upload Audio/Video File</h3>
                <input 
                    type="file" 
                    id="fileInput" 
                    accept="audio/*,video/*,.mp3,.wav,.mp4,.m4a,.webm,.ogg"
                    style="display: none;"
                    onchange="handleFileSelect(event)">
                <button 
                    onclick="document.getElementById('fileInput').click()" 
                    style="padding: 15px 30px; font-size: 16px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 50px; cursor: pointer; font-weight: bold; box-shadow: 0 5px 15px rgba(0,0,0,0.2);">
                    üì§ Choose File to Transcribe
                </button>
                <p style="margin-top: 15px; color: #7f8c8d; font-size: 14px;">
                    Supports: MP3, WAV, MP4, M4A, WebM, OGG<br>
                    Perfect for Zoom/Teams recordings!
                </p>
                <div id="fileProgress" style="display: none; margin-top: 15px;">
                    <div style="background: #e0e0e0; border-radius: 10px; height: 20px; overflow: hidden;">
                        <div id="progressBar" style="background: linear-gradient(90deg, #667eea, #764ba2); height: 100%; width: 0%; transition: width 0.3s;"></div>
                    </div>
                    <p id="progressText" style="margin-top: 10px; font-weight: bold; color: #667eea;">Processing...</p>
                </div>
            </div>

            <div style="text-align: center; color: #95a5a6; margin: 20px 0;">
                ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OR ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            </div>

            <div style="background: #e3f2fd; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 4px solid #2196f3;">
                <strong>üìå Important:</strong> When you click "Start Recording", your browser will ask for microphone permission. 
                <strong>Click "Allow this time"</strong> or <strong>"Allow while visiting this site"</strong> to continue.
            </div>

            <div id="message"></div>

            <div class="controls">
                <button id="startBtn" class="btn-start" onclick="startRecording()">
                    üé§ Start Microphone Recording
                </button>
                <button id="startTabBtn" class="btn-start" onclick="startTabRecording()" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);">
                    üñ•Ô∏è Record Browser Tab (With Audio)
                </button>
                <button id="voiceNoteBtn" class="btn-start" onclick="toggleVoiceNote()" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);">
                    üéôÔ∏è Record Voice Note
                </button>
                <button id="stopBtn" class="btn-stop" onclick="stopRecording()" style="display: none;">
                    ‚èπ Stop Recording
                </button>
                <div id="recordingIndicator" style="display: none;" class="recording-indicator">
                    <span class="pulse">‚óè</span> Recording...
                </div>
                <div id="voiceNoteRecorder" style="display: none; margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 10px; border: 2px solid #f093fb;">
                    <h3 style="color: #f5576c; margin-bottom: 15px;">üéôÔ∏è Voice Note Recorder</h3>
                    <p style="margin-bottom: 15px; color: #7f8c8d;">Press and hold to record, release to stop</p>
                    <button id="voiceNoteRecordBtn" 
                            onmousedown="startVoiceNote()" 
                            onmouseup="stopVoiceNote()" 
                            ontouchstart="startVoiceNote(event)" 
                            ontouchend="stopVoiceNote(event)"
                            style="width: 100%; padding: 40px; font-size: 18px; background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; border: none; border-radius: 10px; cursor: pointer; font-weight: bold;">
                        HOLD TO RECORD
                    </button>
                    <div id="voiceNoteStatus" style="margin-top: 15px; text-align: center; font-weight: bold; color: #667eea;"></div>
                    <div id="voiceNotePlayer" style="display: none; margin-top: 15px;">
                        <audio id="voiceNoteAudio" controls style="width: 100%;"></audio>
                        <div style="display: flex; gap: 10px; margin-top: 10px;">
                            <button onclick="transcribeVoiceNote()" style="flex: 1; padding: 12px; background: #667eea; color: white; border: none; border-radius: 5px; cursor: pointer;">
                                ‚ú® Transcribe
                            </button>
                            <button onclick="discardVoiceNote()" style="flex: 1; padding: 12px; background: #e74c3c; color: white; border: none; border-radius: 5px; cursor: pointer;">
                                üóëÔ∏è Discard
                            </button>
                        </div>
                    </div>
                </div>
                <p style="margin-top: 15px; font-size: 14px; color: #7f8c8d;">
                    üí° <strong>Tip:</strong> Use "Record Browser Tab" to capture Zoom/Teams meetings with internal audio!
                </p>
            </div>
        </div>

        <div class="card" id="currentTranscriptCard" style="display: none;">
            <h3>Current Transcript:</h3>
            <div class="transcript-box" id="currentTranscript">
                Waiting for speech...
            </div>
        </div>

        <div class="card">
            <h3>Saved Transcripts (<span id="transcriptCount">0</span>)</h3>
            <div id="transcriptList">
                <div class="empty-state">No transcripts yet. Start recording!</div>
            </div>
        </div>
    </div>

    <footer style="text-align: center; padding: 20px; color: #95a5a6; font-size: 14px; margin-top: 40px;">
        <strong>Meeting Transcriber</strong> v0.56 | 
        <a href="https://github.com/brubi0/meeting-transcriber" target="_blank" style="color: #667eea; text-decoration: none;">GitHub</a> | 
        Built with ‚ù§Ô∏è using Deepgram
        <br>
        <span style="font-size: 12px;">Last updated: November 12, 2025 | iOS optimized</span>
    </footer>

    <script>
        let mediaRecorder = null;
        let deepgramSocket = null;
        let audioStream = null;
        let finalTranscript = '';
        let transcripts = [];
        
        // Voice note recorder variables
        let voiceNoteRecorder = null;
        let voiceNoteChunks = [];
        let voiceNoteBlob = null;
        
        // Detect iOS
        const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
        const isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);

        // Load saved transcripts and API key from localStorage
        window.onload = function() {
            const savedKey = localStorage.getItem('deepgramApiKey');
            if (savedKey) {
                document.getElementById('apiKey').value = savedKey;
            }

            const savedTranscripts = localStorage.getItem('transcripts');
            if (savedTranscripts) {
                transcripts = JSON.parse(savedTranscripts);
                renderTranscripts();
            }
        };

        async function startRecording() {
            const apiKey = document.getElementById('apiKey').value.trim();
            
            if (!apiKey) {
                showMessage('Please enter your Deepgram API key', 'error');
                return;
            }

            // Save API key
            localStorage.setItem('deepgramApiKey', apiKey);

            try {
                showMessage('Requesting microphone access... Please click "Allow" when prompted.', 'success');
                finalTranscript = '';
                document.getElementById('currentTranscript').textContent = 'Waiting for speech...';
                document.getElementById('currentTranscriptCard').style.display = 'block';

                // Get microphone access
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                }).catch(error => {
                    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                        showMessage('‚ùå Microphone access denied. Please click "Allow" in the browser prompt and try again.', 'error');
                    } else if (error.name === 'NotFoundError') {
                        showMessage('‚ùå No microphone found. Please connect a microphone and try again.', 'error');
                    } else {
                        showMessage('‚ùå Microphone error: ' + error.message, 'error');
                    }
                    throw error;
                });

                await startTranscription('microphone');

            } catch (error) {
                console.error('Error starting recording:', error);
                document.getElementById('currentTranscriptCard').style.display = 'none';
            }
        }

        async function startTabRecording() {
            const apiKey = document.getElementById('apiKey').value.trim();
            
            if (!apiKey) {
                showMessage('Please enter your Deepgram API key', 'error');
                return;
            }

            // Save API key
            localStorage.setItem('deepgramApiKey', apiKey);

            try {
                showMessage('Select the browser tab you want to record (make sure to check "Share audio")...', 'success');
                finalTranscript = '';
                document.getElementById('currentTranscript').textContent = 'Waiting for speech...';
                document.getElementById('currentTranscriptCard').style.display = 'block';

                // Get screen/tab capture with audio
                const displayStream = await navigator.mediaDevices.getDisplayMedia({
                    video: true,
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    }
                }).catch(error => {
                    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                        showMessage('‚ùå Screen sharing cancelled. Please select a tab and check "Share audio".', 'error');
                    } else {
                        showMessage('‚ùå Screen capture error: ' + error.message, 'error');
                    }
                    throw error;
                });

                // Check if audio track exists
                const audioTracks = displayStream.getAudioTracks();
                if (audioTracks.length === 0) {
                    displayStream.getTracks().forEach(track => track.stop());
                    showMessage('‚ùå No audio detected. Please make sure to check "Share audio" when selecting the tab.', 'error');
                    document.getElementById('currentTranscriptCard').style.display = 'none';
                    return;
                }

                // Create audio-only stream from the display stream
                audioStream = new MediaStream(audioTracks);
                
                console.log('Audio tracks found:', audioTracks.length);
                console.log('Audio track settings:', audioTracks[0].getSettings());
                console.log('Audio stream:', audioStream);
                
                // Keep reference to video track for stop detection
                window.videoTrack = displayStream.getVideoTracks()[0];
                
                // Handle tab/screen sharing being stopped by user
                window.videoTrack.addEventListener('ended', () => {
                    console.log('Screen sharing stopped by user');
                    stopRecording();
                });

                showMessage('‚úÖ Audio detected! Starting transcription...', 'success');
                await startTranscription('browser tab');

            } catch (error) {
                console.error('Error starting tab recording:', error);
                document.getElementById('currentTranscriptCard').style.display = 'none';
            }
        }

        async function startTranscription(source) {
            try {
                const apiKey = document.getElementById('apiKey').value.trim();
                const wsUrl = `wss://api.deepgram.com/v1/listen?model=nova-2&language=multi&smart_format=true&punctuate=true&interim_results=true`;
                
                deepgramSocket = new WebSocket(wsUrl, ['token', apiKey]);
                
                deepgramSocket.onopen = () => {
                    console.log('Deepgram connection opened');
                    showMessage(`‚úÖ Connected! Recording from ${source}...`, 'success');
                };

                deepgramSocket.onmessage = (message) => {
                    const data = JSON.parse(message.data);
                    const transcript = data.channel?.alternatives?.[0];
                    if (transcript && transcript.transcript) {
                        if (data.is_final) {
                            finalTranscript += transcript.transcript + ' ';
                            document.getElementById('currentTranscript').textContent = finalTranscript;
                        } else {
                            document.getElementById('currentTranscript').textContent = finalTranscript + transcript.transcript;
                        }
                    }
                };

                deepgramSocket.onerror = (error) => {
                    console.error('Deepgram error:', error);
                    showMessage('Connection error. Check your API key.', 'error');
                };

                deepgramSocket.onclose = () => {
                    console.log('Deepgram connection closed');
                };

                // Setup MediaRecorder with iOS-compatible settings
                let mimeType = 'audio/webm';
                if (isIOS || isSafari) {
                    // iOS Safari doesn't support webm, use mp4
                    if (MediaRecorder.isTypeSupported('audio/mp4')) {
                        mimeType = 'audio/mp4';
                    } else if (MediaRecorder.isTypeSupported('audio/wav')) {
                        mimeType = 'audio/wav';
                    }
                }
                
                console.log('Using mimeType:', mimeType);
                
                mediaRecorder = new MediaRecorder(audioStream, {
                    mimeType: mimeType
                });

                mediaRecorder.ondataavailable = async (event) => {
                    if (event.data.size > 0 && deepgramSocket && deepgramSocket.readyState === WebSocket.OPEN) {
                        const arrayBuffer = await event.data.arrayBuffer();
                        deepgramSocket.send(arrayBuffer);
                    }
                };

                mediaRecorder.start(250);

                // Update UI
                document.getElementById('startBtn').style.display = 'none';
                document.getElementById('startTabBtn').style.display = 'none';
                document.getElementById('stopBtn').style.display = 'inline-block';
                document.getElementById('recordingIndicator').style.display = 'block';
                document.getElementById('apiKey').disabled = true;

            } catch (error) {
                console.error('Error starting transcription:', error);
                showMessage('Failed to start: ' + error.message, 'error');
            }
        }

        function stopRecording() {
            // Prevent multiple clicks
            const stopBtn = document.getElementById('stopBtn');
            if (stopBtn.disabled) return;
            stopBtn.disabled = true;

            try {
                if (mediaRecorder) {
                    mediaRecorder.stop();
                    mediaRecorder = null;
                }

                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                    audioStream = null;
                }

                // Stop video track if it exists (from tab recording)
                if (window.videoTrack) {
                    window.videoTrack.stop();
                    window.videoTrack = null;
                }

                if (deepgramSocket) {
                    deepgramSocket.close();
                    deepgramSocket = null;
                }

                // Save transcript
                if (finalTranscript.trim()) {
                    const newTranscript = {
                        id: Date.now(),
                        title: 'Recording ' + new Date().toLocaleString(),
                        text: finalTranscript.trim(),
                        date: new Date().toISOString()
                    };

                    transcripts.unshift(newTranscript);
                    localStorage.setItem('transcripts', JSON.stringify(transcripts));
                    renderTranscripts();

                    showMessage('Transcript saved!', 'success');
                }

                // Update UI
                document.getElementById('startBtn').style.display = 'inline-block';
                document.getElementById('startTabBtn').style.display = 'inline-block';
                document.getElementById('stopBtn').style.display = 'none';
                document.getElementById('recordingIndicator').style.display = 'none';
                document.getElementById('apiKey').disabled = false;
                stopBtn.disabled = false;

            } catch (error) {
                console.error('Error stopping recording:', error);
                showMessage('Failed to stop recording: ' + error.message, 'error');
                stopBtn.disabled = false;
            }
        }

        function renderTranscripts() {
            const listEl = document.getElementById('transcriptList');
            document.getElementById('transcriptCount').textContent = transcripts.length;

            if (transcripts.length === 0) {
                listEl.innerHTML = '<div class="empty-state">No transcripts yet. Start recording!</div>';
                return;
            }

            listEl.innerHTML = transcripts.map(t => `
                <div class="transcript-item">
                    <div class="transcript-title">${t.title}</div>
                    <div class="transcript-preview">${t.text.substring(0, 150)}...</div>
                    <button class="btn-export" onclick="exportTranscript(${t.id})">üì• Export Transcript</button>
                    <button class="btn-export" onclick="deleteTranscript(${t.id})" style="background: #e74c3c;">üóëÔ∏è Delete</button>
                    <div class="ai-actions" id="ai-actions-${t.id}">
                        <button class="btn-ai" onclick="exportWithPrompt(${t.id}, 'summarize')">‚ú® Export: Summarize</button>
                        <button class="btn-ai" onclick="exportWithPrompt(${t.id}, 'action-items')">üìã Export: Action Items</button>
                        <button class="btn-ai" onclick="exportWithPrompt(${t.id}, 'key-points')">üîë Export: Key Points</button>
                        <button class="btn-ai" onclick="exportWithPrompt(${t.id}, 'minutes')">üìù Export: Meeting Minutes</button>
                    </div>
                </div>
            `).join('');
        }

        function exportTranscript(id) {
            const transcript = transcripts.find(t => t.id === id);
            if (!transcript) return;

            const blob = new Blob([transcript.text], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = transcript.title + '.txt';
            a.click();
            URL.revokeObjectURL(url);
        }

        function deleteTranscript(id) {
            if (confirm('Delete this transcript?')) {
                transcripts = transcripts.filter(t => t.id !== id);
                localStorage.setItem('transcripts', JSON.stringify(transcripts));
                renderTranscripts();
            }
        }

        function showMessage(msg, type) {
            const el = document.getElementById('message');
            if (!msg) {
                el.innerHTML = '';
                return;
            }
            el.innerHTML = `<div class="${type}">${msg}</div>`;
        }

        // Export transcript with AI analysis prompt
        function exportWithPrompt(transcriptId, promptType) {
            const transcript = transcripts.find(t => t.id === transcriptId);
            if (!transcript) return;

            let prompt = '';
            let filename = '';

            switch(promptType) {
                case 'summarize':
                    prompt = `Please provide a concise 2-3 sentence summary of this meeting transcript:\n\n${transcript.text}`;
                    filename = `${transcript.title} - Summarize.txt`;
                    break;
                case 'action-items':
                    prompt = `Extract all action items from this meeting transcript. Format as a bulleted list with the task and who is responsible (if mentioned):\n\n${transcript.text}`;
                    filename = `${transcript.title} - Action Items.txt`;
                    break;
                case 'key-points':
                    prompt = `List the key points and main topics discussed in this meeting as bullet points:\n\n${transcript.text}`;
                    filename = `${transcript.title} - Key Points.txt`;
                    break;
                case 'minutes':
                    prompt = `Create professional meeting minutes from this transcript. Include: attendees (if mentioned), key discussion points, decisions made, and action items:\n\n${transcript.text}`;
                    filename = `${transcript.title} - Meeting Minutes.txt`;
                    break;
            }

            const blob = new Blob([prompt], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            a.click();
            URL.revokeObjectURL(url);

            showMessage(`üì• Exported! Now copy the text and paste into claude.ai for analysis.`, 'success');
        }

        // Handle file upload for transcription
        async function handleFileSelect(event) {
            const file = event.target.files[0];
            if (!file) return;

            const apiKey = document.getElementById('apiKey').value.trim();
            if (!apiKey) {
                showMessage('Please enter your Deepgram API key first', 'error');
                event.target.value = '';
                return;
            }

            // Check file size (max 2GB for Deepgram, but recommend smaller)
            const maxSize = 500 * 1024 * 1024; // 500MB recommended limit
            if (file.size > maxSize) {
                showMessage('File too large. Please use a file under 500MB.', 'error');
                event.target.value = '';
                return;
            }

            try {
                showMessage('', '');
                document.getElementById('fileProgress').style.display = 'block';
                document.getElementById('progressText').textContent = 'Uploading to Deepgram...';
                document.getElementById('progressBar').style.width = '30%';

                // Use Deepgram's pre-recorded API
                const response = await fetch('https://api.deepgram.com/v1/listen?model=nova-2&language=multi&smart_format=true&punctuate=true', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Token ${apiKey}`,
                        'Content-Type': file.type || 'application/octet-stream'
                    },
                    body: file
                });

                document.getElementById('progressBar').style.width = '70%';
                document.getElementById('progressText').textContent = 'Processing transcription...';

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.err_msg || 'Transcription failed');
                }

                const data = await response.json();
                document.getElementById('progressBar').style.width = '100%';
                document.getElementById('progressText').textContent = 'Complete!';

                // Extract transcript
                const transcript = data.results?.channels?.[0]?.alternatives?.[0]?.transcript;
                
                if (!transcript || transcript.trim() === '') {
                    throw new Error('No speech detected in file. Please check the audio quality.');
                }

                // Save transcript
                const newTranscript = {
                    id: Date.now(),
                    title: `File: ${file.name} - ${new Date().toLocaleString()}`,
                    text: transcript.trim(),
                    date: new Date().toISOString()
                };

                transcripts.unshift(newTranscript);
                localStorage.setItem('transcripts', JSON.stringify(transcripts));
                renderTranscripts();

                showMessage(`‚úÖ File transcribed successfully! Found ${transcript.split(' ').length} words.`, 'success');
                
                // Scroll to transcripts
                document.getElementById('transcriptList').scrollIntoView({ behavior: 'smooth' });

            } catch (error) {
                console.error('File transcription error:', error);
                showMessage(`‚ùå Transcription failed: ${error.message}`, 'error');
            } finally {
                // Reset file input and progress
                event.target.value = '';
                setTimeout(() => {
                    document.getElementById('fileProgress').style.display = 'none';
                    document.getElementById('progressBar').style.width = '0%';
                }, 2000);
            }
        }

        // Voice Note Recorder Functions
        function toggleVoiceNote() {
            const recorder = document.getElementById('voiceNoteRecorder');
            if (recorder.style.display === 'none') {
                recorder.style.display = 'block';
                document.getElementById('voiceNoteBtn').textContent = '‚ùå Close Voice Note';
            } else {
                recorder.style.display = 'none';
                document.getElementById('voiceNoteBtn').textContent = 'üéôÔ∏è Record Voice Note';
                discardVoiceNote();
            }
        }

        async function startVoiceNote(event) {
            if (event) event.preventDefault();
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                voiceNoteChunks = [];
                
                // Use iOS-compatible MIME type
                let mimeType = 'audio/webm';
                if (isIOS || isSafari) {
                    if (MediaRecorder.isTypeSupported('audio/mp4')) {
                        mimeType = 'audio/mp4';
                    }
                }
                
                voiceNoteRecorder = new MediaRecorder(stream, { mimeType });
                
                voiceNoteRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) {
                        voiceNoteChunks.push(e.data);
                    }
                };
                
                voiceNoteRecorder.onstop = () => {
                    voiceNoteBlob = new Blob(voiceNoteChunks, { type: mimeType });
                    const url = URL.createObjectURL(voiceNoteBlob);
                    const audio = document.getElementById('voiceNoteAudio');
                    audio.src = url;
                    document.getElementById('voiceNotePlayer').style.display = 'block';
                    document.getElementById('voiceNoteStatus').textContent = '‚úÖ Recording saved! Listen or transcribe below.';
                    
                    // Stop all tracks
                    stream.getTracks().forEach(track => track.stop());
                };
                
                voiceNoteRecorder.start();
                document.getElementById('voiceNoteStatus').textContent = 'üî¥ Recording... (Release to stop)';
                document.getElementById('voiceNoteRecordBtn').style.background = 'linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)';
                
            } catch (error) {
                console.error('Voice note error:', error);
                showMessage('Failed to start voice note: ' + error.message, 'error');
            }
        }

        function stopVoiceNote(event) {
            if (event) event.preventDefault();
            
            if (voiceNoteRecorder && voiceNoteRecorder.state === 'recording') {
                voiceNoteRecorder.stop();
                document.getElementById('voiceNoteRecordBtn').style.background = 'linear-gradient(135deg, #f093fb 0%, #f5576c 100%)';
            }
        }

        async function transcribeVoiceNote() {
            if (!voiceNoteBlob) return;
            
            const apiKey = document.getElementById('apiKey').value.trim();
            if (!apiKey) {
                showMessage('Please enter your Deepgram API key first', 'error');
                return;
            }
            
            try {
                document.getElementById('voiceNoteStatus').textContent = '‚è≥ Transcribing...';
                
                const response = await fetch('https://api.deepgram.com/v1/listen?model=nova-2&language=multi&smart_format=true&punctuate=true', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Token ${apiKey}`,
                        'Content-Type': voiceNoteBlob.type
                    },
                    body: voiceNoteBlob
                });
                
                if (!response.ok) {
                    throw new Error('Transcription failed');
                }
                
                const data = await response.json();
                const transcript = data.results?.channels?.[0]?.alternatives?.[0]?.transcript;
                
                if (!transcript || transcript.trim() === '') {
                    throw new Error('No speech detected in voice note');
                }
                
                // Save transcript
                const newTranscript = {
                    id: Date.now(),
                    title: `Voice Note - ${new Date().toLocaleString()}`,
                    text: transcript.trim(),
                    date: new Date().toISOString()
                };
                
                transcripts.unshift(newTranscript);
                localStorage.setItem('transcripts', JSON.stringify(transcripts));
                renderTranscripts();
                
                showMessage('‚úÖ Voice note transcribed successfully!', 'success');
                document.getElementById('voiceNoteStatus').textContent = '‚úÖ Transcribed!';
                
                // Scroll to transcripts
                document.getElementById('transcriptList').scrollIntoView({ behavior: 'smooth' });
                
                // Clean up
                setTimeout(() => {
                    discardVoiceNote();
                    toggleVoiceNote();
                }, 2000);
                
            } catch (error) {
                console.error('Transcription error:', error);
                showMessage('Failed to transcribe: ' + error.message, 'error');
                document.getElementById('voiceNoteStatus').textContent = '‚ùå Transcription failed';
            }
        }

        function discardVoiceNote() {
            if (voiceNoteBlob) {
                URL.revokeObjectURL(document.getElementById('voiceNoteAudio').src);
            }
            voiceNoteBlob = null;
            voiceNoteChunks = [];
            document.getElementById('voiceNotePlayer').style.display = 'none';
            document.getElementById('voiceNoteStatus').textContent = '';
            document.getElementById('voiceNoteAudio').src = '';
        }

        // Hide tab recording button on mobile (not supported)
        window.addEventListener('load', function() {
            if (isIOS || /Android/.test(navigator.userAgent)) {
                document.getElementById('startTabBtn').style.display = 'none';
            }
        });
    </script>
</body>
</html>
